{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import warnings\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Ignore specific warnings from imblearn\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data and Initial Cleaning\n",
    "# Define the path to the dataset\n",
    "file_path = \"dataset/Dataset.csv\"\n",
    "\n",
    "# Load dataset with error handling\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Dataset file not found at '{file_path}'. Please ensure the path is correct.\")\n",
    "    df = pd.DataFrame() # Create an empty DataFrame to avoid errors\n",
    "\n",
    "# Proceed only if the DataFrame was loaded successfully\n",
    "if not df.empty:\n",
    "    # Rename columns\n",
    "    df = df.rename(columns={\n",
    "        'Restaurant Name': 'name',\n",
    "        'Cuisines': 'cuisines',\n",
    "        'Average Cost for two': 'cost',\n",
    "        'Has Online delivery': 'online_order',\n",
    "        'Has Table booking': 'book_table',\n",
    "        'Aggregate rating': 'rating',\n",
    "        'Rating color': 'rating_color',\n",
    "        'Rating text': 'rating_text',\n",
    "        'Price range': 'price_range_cat',\n",
    "        'Votes': 'votes'\n",
    "    })\n",
    "\n",
    "    # Drop rows where the target variable 'cuisines' is missing\n",
    "    df.dropna(subset=['cuisines'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb6bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Rare Cuisine Classes and Encode Target\n",
    "if not df.empty and 'cuisines' in df.columns:\n",
    "    # Ensure the 'cuisines' column is treated as string data\n",
    "    df['cuisines'] = df['cuisines'].astype(str)\n",
    "\n",
    "    # Filter out cuisine classes with very few samples\n",
    "    min_samples_threshold = 10 # Define the minimum number of restaurants required for a cuisine class\n",
    "    cuisine_counts = df['cuisines'].value_counts()\n",
    "    cuisines_to_keep = cuisine_counts[cuisine_counts >= min_samples_threshold].index\n",
    "    df = df[df['cuisines'].isin(cuisines_to_keep)].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Encode the target variable 'cuisines' into numerical labels\n",
    "    if not df['cuisines'].empty:\n",
    "        le = LabelEncoder()\n",
    "        df['cuisine_encoded'] = le.fit_transform(df['cuisines'])\n",
    "        # Store the mapping from cuisine name to encoded label for later interpretation\n",
    "        cuisine_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    else:\n",
    "        print(\"Warning: 'cuisines' column is empty after filtering. Cannot encode.\")\n",
    "        df = pd.DataFrame() # Clear df to prevent errors\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame is empty or 'cuisines' column is missing. Cannot handle rare classes or encode target.\")\n",
    "    if 'df' in locals() and not isinstance(df, pd.DataFrame):\n",
    "         df = pd.DataFrame()\n",
    "    elif 'df' not in locals():\n",
    "         df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Features (Numerical, Categorical, and Text)\n",
    "# Proceed only if the DataFrame is not empty and the target has been encoded\n",
    "if not df.empty and 'cuisine_encoded' in df.columns:\n",
    "\n",
    "    # Define Feature Sets\n",
    "    numerical_features = ['cost', 'rating', 'votes']\n",
    "    categorical_features = ['online_order', 'book_table']\n",
    "    text_feature_col = 'cuisines'\n",
    "\n",
    "    # Impute Missing Values in Selected Feature Columns\n",
    "    # Numerical features: Impute with median\n",
    "    for col in numerical_features:\n",
    "        if col in df.columns:\n",
    "            if df[col].isnull().any():\n",
    "                median_val = df[col].median()\n",
    "                df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "    # Categorical features: Impute with 'Unknown'\n",
    "    for col in categorical_features:\n",
    "         if col in df.columns:\n",
    "             if df[col].isnull().any():\n",
    "                 if df[col].dtype != 'object':\n",
    "                     df[col] = df[col].astype(object)\n",
    "                 df[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "    # Identify features actually available after checks\n",
    "    available_numerical_features = [f for f in numerical_features if f in df.columns]\n",
    "    available_categorical_features = [f for f in categorical_features if f in df.columns]\n",
    "\n",
    "    # Feature Engineering: Create Text Features using TF-IDF\n",
    "    X_text = None\n",
    "    if text_feature_col in df.columns:\n",
    "        tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=3000, ngram_range=(1, 1))\n",
    "        X_text = tfidf_vectorizer.fit_transform(df[text_feature_col])\n",
    "\n",
    "\n",
    "    # Feature Engineering: Handle Categorical Features using One-Hot Encoding\n",
    "    X_cat_encoded = None\n",
    "    if available_categorical_features:\n",
    "        X_cat = df[available_categorical_features]\n",
    "        try:\n",
    "            X_cat_encoded = pd.get_dummies(X_cat, columns=available_categorical_features, drop_first=True, dummy_na=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during One-Hot Encoding: {e}\")\n",
    "            X_cat_encoded = None\n",
    "\n",
    "    # Combine all feature types into a single feature matrix\n",
    "    feature_list = []\n",
    "\n",
    "    # Add numerical features\n",
    "    if available_numerical_features:\n",
    "        X_num = df[available_numerical_features].values\n",
    "        if X_num.size > 0:\n",
    "             feature_list.append(sp.csr_matrix(X_num))\n",
    "\n",
    "\n",
    "    # Add encoded categorical features\n",
    "    if X_cat_encoded is not None and not X_cat_encoded.empty:\n",
    "         feature_list.append(sp.csr_matrix(X_cat_encoded.values))\n",
    "\n",
    "\n",
    "    # Add TF-IDF text features\n",
    "    if X_text is not None:\n",
    "        feature_list.append(X_text)\n",
    "\n",
    "\n",
    "    # Horizontally stack all sparse feature matrices\n",
    "    if feature_list:\n",
    "        X_combined = sp.hstack(feature_list, format='csr')\n",
    "        y = df['cuisine_encoded'] # Define the target variable\n",
    "\n",
    "        # Final Sanity Check: Ensure features and target align\n",
    "        if X_combined.shape[0] != len(y):\n",
    "            print(f\"CRITICAL ERROR: Feature matrix ({X_combined.shape[0]} samples) and target ({len(y)} samples) have different lengths. Check data processing steps.\")\n",
    "            if 'X_combined' in locals(): del X_combined\n",
    "            if 'y' in locals(): del y\n",
    "    else:\n",
    "        print(\"No features were successfully processed or combined. Cannot create combined feature matrix.\")\n",
    "        if 'X_combined' in locals(): del X_combined\n",
    "        if 'y' in locals(): del y\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame is empty or target column ('cuisine_encoded') is missing. Cannot prepare features.\")\n",
    "    if 'X_combined' in locals(): del X_combined\n",
    "    if 'y' in locals(): del y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b893f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data and Apply SMOTE\n",
    "# Proceed only if the combined feature matrix and target variable exist\n",
    "if 'X_combined' in locals() and 'y' in locals():\n",
    "    # Split data into training and testing sets\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_combined, y,\n",
    "            test_size=0.25,\n",
    "            random_state=42,\n",
    "            stratify=y\n",
    "        )\n",
    "\n",
    "\n",
    "        # Apply SMOTE to the training data ONLY\n",
    "        min_class_size_train = y_train.value_counts().min()\n",
    "        smote_k = max(1, min(2, min_class_size_train - 1))\n",
    "\n",
    "        # Check if any class is too small for SMOTE\n",
    "        if min_class_size_train > smote_k :\n",
    "            try:\n",
    "                nn = NearestNeighbors(n_neighbors=smote_k)\n",
    "                smote = SMOTE(random_state=42, k_neighbors=nn)\n",
    "                X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error applying SMOTE: {e}\")\n",
    "                X_train_resampled = X_train\n",
    "                y_train_resampled = y_train\n",
    "        else:\n",
    "            print(f\"Warning: Smallest class size ({min_class_size_train}) is not large enough for SMOTE with k={smote_k}. Proceeding without SMOTE.\")\n",
    "            X_train_resampled = X_train\n",
    "            y_train_resampled = y_train\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error during train_test_split: {e}\")\n",
    "        if 'X_train' in locals(): del X_train, X_test, y_train, y_test\n",
    "        if 'X_train_resampled' in locals(): del X_train_resampled, y_train_resampled\n",
    "\n",
    "else:\n",
    "    print(\"Combined feature matrix ('X_combined') or target ('y') is not available. Cannot split data or apply SMOTE.\")\n",
    "    if 'X_train' in locals(): del X_train, X_test, y_train, y_test\n",
    "    if 'X_train_resampled' in locals(): del X_train_resampled, y_train_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a33cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and Train the Model\n",
    "# Proceed only if the (potentially resampled) training data is available\n",
    "if 'X_train_resampled' in locals() and 'y_train_resampled' in locals() and X_train_resampled.shape[0] > 0:\n",
    "    # Select a classification model: RandomForestClassifier\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    # Train the model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "else:\n",
    "    print(\"Training data ('X_train_resampled', 'y_train_resampled') is not available or is empty. Cannot train the model.\")\n",
    "    if 'model' in locals(): del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cbd1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "# Proceed only if the model was trained and the original test data exists\n",
    "if 'model' in locals() and 'X_test' in locals() and 'y_test' in locals() and X_test.shape[0] > 0:\n",
    "    # Make predictions on the ORIGINAL test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate Model Performance\n",
    "    print(\"\\n--- Model Evaluation Results ---\")\n",
    "\n",
    "    # Ensure the LabelEncoder (le) and its mapping are available from Cell 3\n",
    "    if 'le' in locals() and hasattr(le, 'classes_'):\n",
    "        target_names = le.classes_ # Get the original cuisine names\n",
    "\n",
    "        # Get unique labels present in either y_test or y_pred\n",
    "        present_labels = np.unique(np.concatenate((y_test, y_pred)))\n",
    "\n",
    "        # Filter target names to include only those present in the test/pred set\n",
    "        valid_indices = [i for i in present_labels if i < len(target_names)]\n",
    "        filtered_target_names = [target_names[i] for i in valid_indices]\n",
    "\n",
    "        if not valid_indices:\n",
    "             print(\"Warning: No valid labels found in test/predictions matching the encoder. Cannot generate report with names.\")\n",
    "             print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        else:\n",
    "            try:\n",
    "                # Generate classification report\n",
    "                print(classification_report(y_test, y_pred, labels=valid_indices, target_names=filtered_target_names, zero_division=0))\n",
    "            except Exception as e:\n",
    "                 print(f\"Error generating classification report with target names: {e}\")\n",
    "                 print(\"Showing report with encoded labels instead:\")\n",
    "                 print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    else:\n",
    "         print(\"LabelEncoder 'le' not found or invalid. Showing report with encoded labels only:\")\n",
    "         print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Model, test features ('X_test'), or test target ('y_test') is not available or test set is empty. Cannot evaluate the model.\")\n",
    "\n",
    "print(\"\\n--- End of Core Workflow ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753acd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Visualization for Cuisine Classification Task ---\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Proceed only if DataFrame is not empty\n",
    "if not df.empty:\n",
    "\n",
    "    # Step 1: Count the number of restaurants per cuisine\n",
    "    cuisine_counts = df['cuisines'].value_counts()\n",
    "\n",
    "    # Step 2: Select the top 20 cuisines\n",
    "    top_20_cuisines = cuisine_counts.head(20)\n",
    "\n",
    "    # Step 3: Create a DataFrame for easier plotting with hue\n",
    "    cuisine_df = top_20_cuisines.reset_index()\n",
    "    cuisine_df.columns = ['cuisine', 'count']\n",
    "\n",
    "    # Step 4: Plot\n",
    "    plt.figure(figsize=(12,8))\n",
    "    sns.barplot(data=cuisine_df, x='count', y='cuisine', hue='cuisine', palette='viridis', legend=False)\n",
    "    plt.title('Top 20 Most Common Cuisines')\n",
    "    plt.xlabel('Number of Restaurants')\n",
    "    plt.ylabel('Cuisine')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Rating Distribution\n",
    "    if 'rating' in df.columns:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.histplot(df['rating'], bins=20, kde=True, color='skyblue')\n",
    "        plt.title('Distribution of Aggregate Ratings')\n",
    "        plt.xlabel('Rating')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Votes Distribution\n",
    "    if 'votes' in df.columns:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.histplot(df['votes'], bins=30, kde=True, color='salmon')\n",
    "        plt.title('Distribution of Votes')\n",
    "        plt.xlabel('Votes')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Scatter Plot: Cost vs Rating\n",
    "    if 'cost' in df.columns and 'rating' in df.columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.scatterplot(data=df, x='cost', y='rating', hue='cuisines', palette='tab20', legend=False, alpha=0.7)\n",
    "        plt.title('Cost vs Rating Scatter Plot')\n",
    "        plt.xlabel('Average Cost for Two')\n",
    "        plt.ylabel('Aggregate Rating')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Correlation Heatmap\n",
    "    numerical_cols = ['cost', 'rating', 'votes']\n",
    "    available_numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
    "\n",
    "    if available_numerical_cols:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        corr_matrix = df[available_numerical_cols].corr()\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "        plt.title('Correlation Heatmap (Numerical Features)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame is empty. Skipping data visualization.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
